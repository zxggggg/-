
opencv fisheye官网介绍：：：：：：：：https://docs.opencv.org/3.0.0/db/d58/group__calib3d__fisheye.html#gga91b6a47d784dd47ea2c76ef656d7c3dca0899eaa2f96d6eed9927c4b4f4464e05

相机标定步骤：：：：：：：

1. 将待标定的标定板影像全部放入一个文件夹中，而后将rename.sh文件也放入该文件夹中，运行rename.sh文件，将所有影像重命名成fish+数字.png格式，数字从1开始

2. 首先调用OpenCV的FindChessboardCorners()来寻找图像上的标定板的角点，

findChessboardCorners(imageGray, board_size, corners, CALIB_CB_ADAPTIVE_THRESH );


3. 再根据标定板的尺寸指定这些角点对应的三维点的三维坐标，再调用fisheye::calibrate()来进行标定，

fisheye::calibrate(object_Points, corners_Seq, image_size, intrinsic_matrix, distortion_coeffs, rotation_vectors, translation_vectors, flags, cv::TermCriteria(3, 20, 1e-6));


4. 利用标定结果中的内参和畸变参数调用fisheye::initUndistortRectifyMap()对图像做去畸变操作。。

fisheye::initUndistortRectifyMap(intrinsic_matrix,distortion_coeffs,R,intrinsic_matrix,image_size,CV_32FC1,mapx,mapy);

其中，OpenCV中对畸变图像进行畸变校正主要用的函数有UndistortImage()函数，以及initUndistortRectifyMap()结合remap()函数。其实UndistortImage()就是initUndistortRectifyMap()和remap()的简单组合，效果是一样的。
但是有一点是：当你有很多畸变图像需要较正时，用UndistortImage()函数的缺点就暴露了。因为畸变坐标映射矩阵mapx和mapy只需要计算一次就足够了，而重复调用UndistortImage()只会重复计算mapx和mapy，严重影响程序效率。因此当有多张图片要畸变校正时，建议使用一次initUndistortRectifyMap()，获取畸变坐标映射矩阵mapx和mapy后，作为remap函数的输入，多次调用remap函数进行畸变校正。


5. 最后调用所有畸变图片利用标定结果进行畸变校正

每张畸变差的都很多，大概都差0.4~0.5左右，

第1幅图像的平均误差：0.440991像素
第2幅图像的平均误差：0.450458像素
第3幅图像的平均误差：0.454681像素
第4幅图像的平均误差：0.455455像素
第5幅图像的平均误差：0.426937像素
第6幅图像的平均误差：0.418283像素
第7幅图像的平均误差：0.420768像素



下一个别人的数据集试试

官网上的TUM-VI数据集用的是AprilTags网格，而不是普通的标定板

会不会是因为标定板不平整所以才不准的？机房墙壁上的黑白棋盘格纸已经因为年头久了有了褶皱，尝试自己制作25mm标定板

用excel做的精度不够，格网边长不是整mm，而后尝试用ps制作25mm的黑白棋盘格，不知道为什么输出的格子都是24mm的，但是格子是均匀的，也可以用
运行后结果好了很多，

第1幅图像的平均误差：0.082806像素
第2幅图像的平均误差：0.0809513像素
第3幅图像的平均误差：0.0704772像素
第4幅图像的平均误差：0.079779像素
第5幅图像的平均误差：0.0906068像素

总体平均误差：0.0933189像素<0.1个像素，

尝试使用matlab作为比较依据，但是matlab精度很低，平均误差在1左右，输出结果时提示：：：
Image size is not consistent with camera intrinsics. It is likely that the image is not generated by the specified camera.
即图像尺寸与相机的内在特性不一致。 该图像很可能是不是由指定的摄像机生成的。
会不会它以为自己是个全景相机呢？shift
matlab畸变模型系数只有k1,k2,k3，少一个k4。。。。我明明记得哪篇文章说matlab的畸变模型不一样来着？？？？？迷惑

之前做的都是1920×1920相片大小的相机标定，打开yaml文件想写入时突然发现相片大小要512×512的，将影像缩小后在重新运行程序，发现基本所有影像都无法识别角点，开始以为是拍的影像不行，又去重拍，但是打开提取角点文件时发现即使提取出来的角点很多位置不准，尤其是边界处的点，画的圆也过大，因此百度查了提取角点的函数用法：：：：：：

cornerSubPix(imageGray, corners, Size(11, 11), Size(-1, -1), TermCriteria(CV_TERMCRIT_EPS + CV_TERMCRIT_ITER, 30, 0.1));

///////////////////////////////////////////////////////////////////////////////////////////////////////

cv::goodFeaturesToTrack()提取到的角点只能达到像素级别，在很多情况下并不能满足实际的需求，这时，我们则需要使用cv::cornerSubPix()对检测到的角点作进一步的优化计算，可使角点的精度达到亚像素级别。

具体调用形式如下：
    void cv::cornerSubPix(
        cv::InputArray image, // 输入图像
        cv::InputOutputArray corners, // 角点（既作为输入也作为输出）
        cv::Size winSize, // 区域大小为 NXN; N=(winSize*2+1)
        cv::Size zeroZone, // 类似于winSize，但是总具有较小的范围，Size(-1,-1)表示忽略
        cv::TermCriteria criteria // 停止优化的标准
    );

第一个参数是输入图像，和cv::goodFeaturesToTrack()中的输入图像是同一个图像。
第二个参数是检测到的角点，即是输入也是输出。

第三个参数是计算亚像素角点时考虑的区域的大小，大小为NXN; N=(winSize*2+1)。

第四个参数作用类似于winSize，但是总是具有较小的范围，通常忽略（即Size(-1, -1)）。

第五个参数用于表示计算亚像素时停止迭代的标准，可选的值有cv::TermCriteria::MAX_ITER 、cv::TermCriteria::EPS（可以是两者其一，或两者均选），前者表示迭代次数达到了最大次数时停止，后者表示角点位置变化的最小值已经达到最小时停止迭代。二者均使用cv::TermCriteria()构造函数进行指定。

//////////////////////////////////////////////////////////////////////////////////////////////////////////////

尝试调整winSize，重新运行程序，最后把winSize调整成5结果最好，识别输出的影像中，所有的棋盘格内角点都能识别上，而且目视上很准，但是输出的影像还是很少，因此尝试使用新拍的视频
救命啊换了之后1402张还是只有6张识别出来了，winsize调成3也不行，啥玩意啊


不对劲，之前用的512×512的影像是放缩来的，这样精度不够，改用投影
但是投影之后无法保证每个球里都有完整的黑白棋盘格了，shift，还要重新拍aaaaaa


改用投影后，影像投影很多方向拍摄的手在中间，而不是标定板，后来发现可能是相机自己会识别并记录竖直向下的重力方向，自己进行调整，于是需要把相机和标定板都竖着拍，将标定板贴在墙上，但纸很难完全紧贴在墙上无缝隙，难aaaaaa，而且贴完一撕，墙皮都掉了，oh no,oh no ,oh nonononononono

拍好后进行投影和定标，发现还是所有影像都无法识别角点，猜测可能是每次识别角点的数目不对，因为边界有一条小的格子，因此将纸进行裁剪，把边界一圈撕掉，再重新拍摄
lay了

用matlab也识别不了，看来是拍的有问题，好像太近了，再重拍

破案了，就是离得太近了，shift

重拍之后运行程序，感觉没问题了发给师兄，结果师兄说这个结果更不准了，比三维建模得到的结果更漂，用不了，嗷嗷嗷咋会这样呢！！

我不信！！我要自己试一遍！先用师兄的结果跑一下前视

完蛋了，结果真的更差了

会不会是影像选的太多/有不准确的呢，选20多张试一下

选了近处的几张，woc差的更多了，试一下选远处的几张呢

！！！！！fx和fy居然真的变大了！！！！试一下跑一下


不行了这样差的更多了，畸变系数大的不的了，地图都不是一个完整的了

啥玩意啊完肚子了

我giao，好像不同远近的影像的标定参数不同

对啊，那得吧，毕竟远的畸变小啊

影像中的标定板不能太小，不然会报错：：：：：
OpenCV Error: Internal error (CALIB_CHECK_COND - Ill-conditioned matrix for input array 0) in CalibrateExtrinsics, file /tmp/binarydeb/ros-kinetic-opencv3-3.3.1/modules/calib3d/src/fisheye.cpp, line 1406
terminate called after throwing an instance of 'cv::Exception'
  what():  /tmp/binarydeb/ros-kinetic-opencv3-3.3.1/modules/calib3d/src/fisheye.cpp:1406: error: (-3) CALIB_CHECK_COND - Ill-conditioned matrix for input array 0 in function CalibrateExtrinsics


试一下大的跟中等的标定板的区别

中等大小的标定板可以跑起来，有闭环检测，但是结果没有师兄的好
大的标定板很多匹配丢失，只剩后一半线路了，结果无闭环

考虑是由于所用的标定板一直都在中间，四周的边缘都没有，因此重新拍摄，重点拍各种刁钻的角度

天呐这玩意盲拍也太费劲了啊啊啊啊啊啊啊啊啊，下个手机软件试试能不能实时收到影像数据-

啊啊啊啊终于成了，看来标定板影像集要遍布整个影像，保证各个方向都有标定板，进行标定












